{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"B0729064_HW04.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3.7.7 64-bit"},"language_info":{"name":"python","version":"3.7.7","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"interpreter":{"hash":"9164a3399a70d355c381b62813f30880ed90ca5a6f321bf0d85375640bda7ee5"}},"cells":[{"cell_type":"code","execution_count":null,"source":["from google.colab import drive\r\n","drive.mount('/content/drive')"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"33gORW2la6Vc","executionInfo":{"status":"ok","timestamp":1629292876867,"user_tz":-480,"elapsed":41999,"user":{"displayName":"楊永川","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggx1XlzmI8P9pcajCEBcheu4kz3U9OvvaM8dTnb=s64","userId":"08079793556666005334"}},"outputId":"8a46ac43-629e-425f-dae8-d647aa78ceb8"}},{"cell_type":"code","execution_count":1,"source":["import os\r\n","import json\r\n","import jieba\r\n","from opencc import OpenCC\r\n","# from gensim.models import word2vec, fasttext\r\n","#from gensim.models import FastText\r\n","from gensim.models.fasttext import FastText\r\n","\r\n","#path = \"/content/drive/MyDrive/NatureLanguageProgram/B0729064_NLP_HW4/wiki_zh/AA\" #資料夾目錄\r\n","#path = \"C:\\Users\\User\\OneDrive\\桌面\\同步到gAoogle雲端\\NatureLanguageProgram\\B0729064_NLP_HW4/wiki_zh/AA\" #資料夾目錄\r\n","txt = []\r\n","new_txt = []\r\n","def load_data():\r\n","  s = ['AA','AB','AC','AD','AE','AF','AG','AH','AI','AJ','AK','AL','AM']\r\n","  #s = ['AA']\r\n","  cc = OpenCC('s2t')\r\n","\r\n","  for i in s:\r\n","    #path = \"/content/drive/MyDrive/NatureLanguageProgram/B0729064_NLP_HW4/wiki_zh/%s\"%(i)#資料夾目錄\r\n","    path = \"wiki_zh/%s\"%(i)#資料夾目錄\r\n","    files= os.listdir(path) #得到資料夾下的所有檔名稱\r\n","    \r\n","    for file in files: #遍歷資料夾\r\n","      if not os.path.isdir(file): #判斷是否是資料夾，不是資料夾才開啟\r\n","        file = open(path+\"/\"+ file, encoding='utf-8')\r\n","        for line in file.readlines():\r\n","          data = json.loads(line)\r\n","          txt.append(data['text'])\r\n","  for data in txt:\r\n","              data = cc.convert(data)\r\n","              data = jieba.cut(data)\r\n","              data = [word for word in data if word != ' ']\r\n","              data = ' '.join(data)\r\n","              new_txt.append(data)\r\n","              #print(new_txt)\r\n","\r\n","def fasttext():\r\n","  print(\"in model\")\r\n","  sentences = [[\"你\", \"是\", \"誰\"], [\"我\", \"是\", \"中國人\"]]\r\n","\r\n","  # model = FastText(sentences,  vector_size=4, window=3, min_count=1, epochs=10,min_n = 3 , max_n = 6,word_ngrams = 0)\r\n","  # model['你']  # 詞向量獲得的方式 \r\n","  # model.wv['你'] # 詞向量獲得的方式\r\n","\r\n","  # Settings\r\n","  seed = 1000\r\n","  sg = 0\r\n","  window_size = 30\r\n","  vector_size = 1000\r\n","  min_count = 100\r\n","  workers = 10\r\n","  epochs = 10\r\n","  batch_words = 1000\r\n","\r\n","\r\n","  # Train\r\n","  #train_data = word2vec.LineSentence(new_txt)\r\n","  model = FastText(\r\n","      new_txt,\r\n","      # sentences,\r\n","      min_count=min_count,\r\n","      vector_size=vector_size,\r\n","      workers=workers,\r\n","      epochs=epochs,\r\n","      window=window_size,\r\n","      sg=sg,\r\n","      seed=seed,\r\n","      batch_words=batch_words,\r\n","  )\r\n","  model.save('final2.model')\r\n","\r\n","\r\n","if __name__ == '__main__':\r\n","  load_data()\r\n","  fasttext()\r\n","  \r\n","        "],"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"invalid syntax (Temp/ipykernel_26068/3821049985.py, line 4)","traceback":["\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_26068/3821049985.py\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    frm opencc import OpenCC\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1yt3pofdVTSXWgfB_gfSpCZA8BG3wxlkx"},"id":"ZeIbeeAeuT1N","outputId":"dfed9b80-8676-42e9-8b8d-73e384e9e9f1"}},{"cell_type":"code","execution_count":5,"source":["from gensim.models import word2vec\r\n","\r\n","model = word2vec.Word2Vec.load('final.model')\r\n","#print(model.wv['台灣'].shape)\r\n","\r\n","for item in model.wv.most_similar('台灣'):\r\n","    print(item)"],"outputs":[{"output_type":"stream","name":"stdout","text":["('Â', 0.32985153794288635)\n","('咕', 0.32804539799690247)\n","('垚', 0.32747745513916016)\n","('ت', 0.3220761716365814)\n","('砹', 0.31975236535072327)\n","('菲', 0.3155600428581238)\n","('𢧤', 0.3118605613708496)\n","('嚕', 0.3095899820327759)\n","('ل', 0.3026190996170044)\n","('Ω', 0.30206993222236633)\n"]}],"metadata":{"id":"v7mE_Vt0MWCW"}},{"cell_type":"code","execution_count":null,"source":[],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# 線上更新訓練 fasttext\r\n","# from gensim.models import FastText\r\n","# sentences_1 = [[\"cat\", \"say\", \"meow\"], [\"dog\", \"say\", \"woof\"]]\r\n","# sentences_2 = [[\"dude\", \"say\", \"wazzup!\"]]\r\n","\r\n","# model = FastText(min_count=1)\r\n","# model.build_vocab(sentences_1)\r\n","# model.train(sentences_1, total_examples=model.corpus_count, epochs=model.epochs)\r\n","\r\n","# model.build_vocab(sentences_2, update=True)\r\n","# model.train(sentences_2, total_examples=model.corpus_count, epochs=model.epochs)\r\n","# model.save('fname')\r\n","\r\n","from gensim.models import FastText\r\n","sentences = [[\"你\", \"是\", \"誰\"], [\"我\", \"是\", \"中國人\"]]\r\n","\r\n","model = FastText(sentences,  vector_size=4, window=3, min_count=1, epochs=10,min_n = 3 , max_n = 6)\r\n","model['你']  # 詞向量獲得的方式\r\n","model.wv['你'] # 詞向量獲得的方式\r\n","model.save('fname2')"],"outputs":[],"metadata":{}}]}